# Story 30.4: Listening Skill — Quiz Format (Audio + MCQ)

**Status:** Ready for Review
**Epic:** Epic 30 - Skill-Based AI Assignment Generation & Reporting
**Story Points:** 8
**Priority:** High (New skill — core differentiator)
**Dependencies:** Story 30.3 (V2 generation API and dispatcher)

---

## User Story

As a **teacher**,
I want **to generate Listening quiz assignments where students must listen to audio clips to answer questions**,
So that **I can assess and develop my students' listening comprehension skills**.

---

## Acceptance Criteria

1. [ ] Listening Quiz generator produces questions where each has a TTS-generated audio prompt
2. [ ] Student cannot answer without listening — no text transcript of the audio prompt is shown
3. [ ] Answer options are displayed as text (MCQ format)
4. [ ] Audio is generated via the existing TTS provider layer (Edge TTS primary, Azure fallback)
5. [ ] At least 3 listening sub-skill types are supported: gist comprehension, detail extraction, phoneme discrimination
6. [ ] Difficulty levels (CEFR-aligned) affect sentence complexity and question difficulty
7. [ ] Generated audio URLs are stored in `activity_content` alongside question data
8. [ ] Configurable question count (5, 10, 15, 20)

---

## Tasks & Subtasks

- [x] **Task 1: Create Listening Quiz Generator Service** (AC: 1, 5, 6)
  - [x] Create `backend/app/services/ai_generation/listening_quiz_service.py`
  - [x] Implements full pipeline: fetch module → LLM generation → TTS audio → structured output
  - [x] LLM prompt instructs: "Questions must be answerable ONLY by listening"
  - [x] Parallel TTS generation with retry (1 retry, then mark "audio_failed")

- [x] **Task 2: Define Listening Quiz Content Schema** (AC: 1, 7)
  - [x] Create `backend/app/schemas/listening_quiz.py` with full schema
  - [x] ListeningQuizQuestion: audio_text, audio_url, audio_status, sub_skill, MCQ fields
  - [x] ListeningQuizQuestionPublic: excludes audio_text, correct_answer, correct_index
  - [x] ListeningQuizActivity / ListeningQuizActivityPublic

- [x] **Task 3: TTS Audio Generation Integration** (AC: 4, 7)
  - [x] Uses existing TTS manager with Edge TTS provider
  - [x] Generates TTS audio for each question's audio_text in parallel (asyncio.gather)
  - [x] Audio cached by TTS manager; audio_url points to `/api/v1/ai/tts/audio?text=...&lang=...`
  - [x] TTS failure handling: retry once, then mark audio_status="failed"

- [x] **Task 4: Listening Sub-Skill Prompt Variants** (AC: 5)
  - [x] Create `backend/app/services/ai_generation/prompts/listening_prompts.py`
  - [x] 3 sub-skill types: gist (30%), detail (50%), discrimination (20%)
  - [x] CEFR-aligned difficulty guidelines (easy A1-A2, medium A2-B1, hard B1-B2)

- [x] **Task 5: Register in Dispatcher** (AC: 1)
  - [x] Updated GENERATOR_MAP: `("listening", "multiple_choice") → ("listening_quiz", "listening_quiz")`
  - [x] Updated GeneratorKey type to include "listening_quiz"
  - [x] Updated V2 endpoint with listening_quiz routing branch
  - [x] Updated QuizStorageService with save/get/get_public for listening activities

- [x] **Task 6: Unit Tests** (AC: 1-8)
  - [x] 26 tests in `backend/app/tests/test_listening_quiz.py` — all passing
  - [x] Schema tests (7): request validation, question schema, public excludes audio_text/answers
  - [x] Activity tests (2): creation and serialization round-trip
  - [x] Prompt tests (5): build prompt, sub-skill distribution, system prompt, JSON schema, difficulty
  - [x] Service tests (7): full generation, audio URLs, sub-skill dist, TTS failure, no TTS, module not found, auto difficulty
  - [x] Storage tests (3): save/retrieve, public version, nonexistent
  - [x] Updated 30.3 tests: dispatcher now routes listening×mcq (was 501, now success), counts updated

---

## Dev Notes

### TTS Integration
- Existing TTS endpoint: `GET /ai/tts/audio?text={text}&lang={lang}` [Source: epic-27 Story 27.4-27.5]
- Edge TTS provider: `edge-tts` Python library, FREE [Source: epic-27]
- Azure TTS fallback: `turkeycentral` region [Source: epic-27]
- TTS service location: alongside LLM provider in services directory

### DCS Data Available
- Module text: `DCSAIServiceClient.get_module_detail(book_id, module_id)` returns full text + topics
- Vocabulary: available for generating discrimination questions
- CEFR level per module: `difficulty_level` field [Source: epic-27 DCS Integration]

### Key Design Constraint
The audio must be the PRIMARY input. The question text ("What time does the train depart?") is shown, but the information needed to answer (the specific time) is ONLY in the audio. This is what makes it a Listening activity vs. a Reading activity.

### Audio Caching Strategy
- Cache TTS audio with key pattern: `tts:listening:{hash_of_text}:{lang}`
- Cache TTL: 1 hour for presigned URLs (regenerate on demand)
- Store both the text (for regeneration) and the URL (for serving) [Source: epic-27 DCS caching]

### Testing
- Test file: `backend/app/tests/test_listening_quiz_generator.py`
- Mock TTS responses to avoid external calls in tests
- Mock LLM responses with deterministic JSON output

---

## Dev Agent Record

### Agent Model Used
Claude Opus 4.6

### File List
| File | Action | Description |
|------|--------|-------------|
| `backend/app/schemas/listening_quiz.py` | Created | Listening quiz schemas: request, question, activity, public variants |
| `backend/app/services/ai_generation/listening_quiz_service.py` | Created | ListeningQuizService: LLM + TTS pipeline |
| `backend/app/services/ai_generation/prompts/listening_prompts.py` | Created | System/user prompts, JSON schema, sub-skill distribution |
| `backend/app/services/ai_generation/prompts/__init__.py` | Modified | Added listening prompt exports |
| `backend/app/services/skill_generation_dispatcher.py` | Modified | listening×mcq now routes to "listening_quiz" (was None/501) |
| `backend/app/api/routes/ai_generation.py` | Modified | Added listening_quiz branch in V2 endpoint |
| `backend/app/services/ai_generation/quiz_storage_service.py` | Modified | Added save/get/get_public for listening activities |
| `backend/app/tests/test_listening_quiz.py` | Created | 26 unit tests for listening quiz |
| `backend/app/tests/test_ai_generation_v2.py` | Modified | Updated dispatcher test (listening×mcq now dispatches), updated map counts |

### Debug Log References
- No blocking issues encountered.

### Completion Notes
- All 6 tasks implemented and verified
- 26 unit tests passing (test_listening_quiz.py)
- 57 regression tests passing (12 from 30.1 + 16 from 30.2 + 29 from 30.3)
- GENERATOR_MAP now has 8 implemented combos + 4 stubs
- TTS integration uses existing `/tts/audio` endpoint pattern with parallel generation
- audio_text excluded from public schema (students cannot see transcript)
- TTS failure handled gracefully: retry once, then mark "audio_failed"
- Sub-skill distribution: gist 30%, detail 50%, discrimination 20%

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2026-02-12 | 1.0 | Initial story draft | SM Agent (Bob) |
| 2026-02-13 | 1.1 | Implementation complete — all tasks done, 26+57 tests passing | Dev Agent (James) |
