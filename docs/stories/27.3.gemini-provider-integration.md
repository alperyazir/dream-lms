# Story 27.3: Gemini Provider Integration

**Status:** Ready for Review

**Epic:** Epic 27 - DreamAI - AI-Powered Content Generation
**Story Points:** 3
**Priority:** High
**Dependencies:** Story 27.1 (LLM Provider Abstraction Layer)

---

## Story

**As a** system,
**I want** Google Gemini implemented as the fallback LLM provider with vision capabilities,
**so that** content generation can continue when DeepSeek is unavailable and support future image-based features.

---

## Acceptance Criteria

1. [ ] Gemini API client implementation
2. [ ] Support for Gemini 1.5 Flash model
3. [ ] Vision/image analysis support (prepare interface for Phase 2)
4. [ ] PDF native processing support (prepare interface for Phase 2)
5. [ ] Free tier usage optimization
6. [ ] Fallback activation when DeepSeek fails

---

## Tasks / Subtasks

- [x] **Task 1: Create Gemini Provider Class** (AC: 1, 2)
  - [x] Create `backend/app/services/llm/providers/gemini.py`
  - [x] Implement `GeminiProvider` extending `LLMProvider`
  - [x] Configure API endpoint: `https://generativelanguage.googleapis.com/v1beta/models`
  - [x] Use model: `gemini-1.5-flash` (default)
  - [x] Load API key from `GEMINI_API_KEY` environment variable
  - [x] Implement `is_available()` to check API key presence

- [x] **Task 2: Implement Generate Method** (AC: 1, 5)
  - [x] Implement async `generate()` method
  - [x] Build request payload for Gemini API format (differs from OpenAI)
  - [x] Parse Gemini response and extract content
  - [x] Track token usage from response (`usageMetadata`)
  - [x] Calculate cost using TokenUsage.calculate_cost()
  - [x] Measure and return latency_ms
  - [x] Optimize for free tier (handle 60 req/min limit gracefully)

- [x] **Task 3: Implement Structured Generation** (AC: 1)
  - [x] Implement async `generate_structured()` method
  - [x] Use JSON mode via `generationConfig.responseMimeType: "application/json"`
  - [x] Parse JSON response
  - [x] Validate response against schema (basic validation)
  - [x] Handle JSON parsing errors gracefully

- [x] **Task 4: Implement Error Handling and Retry** (AC: 6)
  - [x] Map Gemini API errors to LLMProviderError hierarchy:
    - 401/403 → LLMAuthenticationError
    - 429 → LLMRateLimitError (with retry_after)
    - 500/502/503 → LLMConnectionError
    - Timeout → LLMTimeoutError
  - [x] Implement retry with exponential backoff for transient errors
  - [x] Use settings for max retries and timeout

- [x] **Task 5: Prepare Vision/Image Interface** (AC: 3)
  - [x] Add optional `image_data` parameter to generate methods
  - [x] Add `ContentPart` union type for text/image parts
  - [x] Add docstrings noting vision support is for Phase 2
  - [x] Do NOT implement actual image processing yet (Phase 2 feature)

- [x] **Task 6: Prepare PDF Processing Interface** (AC: 4)
  - [x] Add optional `pdf_data` parameter to generate methods
  - [x] Add docstrings noting PDF support is for Phase 2
  - [x] Do NOT implement actual PDF processing yet (Phase 2 feature)

- [x] **Task 7: Register Provider with Manager** (AC: 1, 6)
  - [x] Update `providers/__init__.py` to export GeminiProvider
  - [x] Update `create_default_manager()` to include Gemini as fallback
  - [x] Ensure manager properly falls back to Gemini when DeepSeek fails

- [x] **Task 8: Write Unit Tests** (AC: All)
  - [x] Test provider initialization
  - [x] Test generate with mocked httpx response
  - [x] Test generate_structured with mocked response
  - [x] Test error mapping for different HTTP status codes
  - [x] Test retry logic
  - [x] Test token usage calculation with Gemini pricing
  - [x] Test fallback activation in manager integration test

---

## Dev Notes

### Previous Story Insights (from 27.2)
[Source: docs/stories/27.2.deepseek-provider-integration.md]

- DeepSeekProvider provides a solid reference implementation
- Uses `httpx.AsyncClient` for async HTTP requests
- Error handling maps HTTP status codes to LLMProviderError hierarchy
- Retry logic uses exponential backoff for transient errors
- `_execute_with_retry()` and `_make_request()` patterns can be replicated

### Source Tree Reference
[Source: architecture/source-tree.md]

New files to create:
```
backend/app/services/llm/
├── providers/
│   ├── __init__.py       # Update to export GeminiProvider
│   ├── deepseek.py       # Existing (reference implementation)
│   └── gemini.py         # NEW
└── ...

backend/app/tests/test_services/test_llm/
├── test_deepseek.py      # Existing (reference for test patterns)
└── test_gemini.py        # NEW
```

### Gemini API Reference

**Endpoint:** `https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent`

**Authentication:** API key via query parameter or header
- Query: `?key={GEMINI_API_KEY}`
- Header: `x-goog-api-key: {GEMINI_API_KEY}`

**Model:** `gemini-1.5-flash` (fast, cost-effective)

**Request Format:**
```json
{
  "contents": [
    {
      "role": "user",
      "parts": [
        {"text": "Your prompt here"}
      ]
    }
  ],
  "generationConfig": {
    "temperature": 0.7,
    "maxOutputTokens": 2000,
    "topP": 1.0,
    "responseMimeType": "application/json"  // For structured output
  }
}
```

**Response Format:**
```json
{
  "candidates": [
    {
      "content": {
        "parts": [
          {"text": "Generated response"}
        ],
        "role": "model"
      },
      "finishReason": "STOP"
    }
  ],
  "usageMetadata": {
    "promptTokenCount": 10,
    "candidatesTokenCount": 20,
    "totalTokenCount": 30
  }
}
```

### Cost Tracking
[Source: epic-27-dreamai-content-generation.md]

- Input: $0.075 per 1M tokens (after free tier)
- Output: $0.30 per 1M tokens (after free tier)
- Free tier: 60 requests per minute, 1M tokens/month
- Already configured in `TokenUsage.calculate_cost()` in base.py

### Error Response Format

Gemini error responses:
```json
{
  "error": {
    "code": 429,
    "message": "Resource has been exhausted...",
    "status": "RESOURCE_EXHAUSTED"
  }
}
```

Status codes to handle:
- 400: INVALID_ARGUMENT - Bad request
- 401/403: UNAUTHENTICATED/PERMISSION_DENIED - Auth error
- 429: RESOURCE_EXHAUSTED - Rate limit
- 500/503: INTERNAL/UNAVAILABLE - Server error

### Vision Capability (Phase 2 - Interface Only)

Gemini supports multimodal input. For Phase 2, the parts array can include:
```json
{
  "parts": [
    {"text": "Describe this image"},
    {
      "inlineData": {
        "mimeType": "image/jpeg",
        "data": "base64_encoded_image"
      }
    }
  ]
}
```

**For this story:** Only add interface parameters and docstrings. Do NOT implement actual vision processing.

### PDF Processing (Phase 2 - Interface Only)

Gemini can process PDFs natively:
```json
{
  "parts": [
    {"text": "Summarize this PDF"},
    {
      "fileData": {
        "mimeType": "application/pdf",
        "fileUri": "gs://bucket/file.pdf"
      }
    }
  ]
}
```

**For this story:** Only add interface parameters and docstrings. Do NOT implement actual PDF processing.

### Coding Standards
[Source: architecture/coding-standards.md]

- Use `async/await` consistently for all provider operations
- Type hints required on all functions
- Use Pydantic for data validation
- Follow snake_case for variables/functions, PascalCase for classes
- Docstrings using Google style
- Error handling with specific HTTPException codes

### Environment Variables
[Source: epic-27-dreamai-content-generation.md]

```bash
# Already defined in config.py from Story 27.1
GEMINI_API_KEY=xxx
LLM_FALLBACK_PROVIDER=gemini
```

---

## Testing

### Test File Location
`backend/app/tests/test_services/test_llm/test_gemini.py`

### Test Standards
[Source: architecture/coding-standards.md]

- Use `pytest` with `pytest-asyncio`
- Mock `httpx.AsyncClient` for API calls
- Use `unittest.mock` or `pytest-mock` for HTTP responses
- Follow arrange-act-assert pattern
- Aim for >80% coverage on new code

### Test Cases Required

```python
# test_gemini.py

# Initialization tests
def test_gemini_provider_init_with_api_key():
    """Test provider initializes with valid API key."""

def test_gemini_provider_init_without_api_key():
    """Test is_available returns False without API key."""

def test_gemini_provider_get_name():
    """Test get_name returns 'gemini'."""

def test_gemini_provider_get_default_model():
    """Test get_default_model returns 'gemini-1.5-flash'."""

# Generate method tests
@pytest.mark.asyncio
async def test_generate_success():
    """Test successful text generation."""

@pytest.mark.asyncio
async def test_generate_with_custom_options():
    """Test generation with custom temperature, max_tokens."""

@pytest.mark.asyncio
async def test_generate_tracks_token_usage():
    """Test token usage is correctly parsed from response."""

@pytest.mark.asyncio
async def test_generate_calculates_cost():
    """Test cost is calculated using Gemini pricing."""

# Structured generation tests
@pytest.mark.asyncio
async def test_generate_structured_success():
    """Test structured JSON output."""

@pytest.mark.asyncio
async def test_generate_structured_invalid_json():
    """Test LLMResponseError raised for invalid JSON."""

# Error handling tests
@pytest.mark.asyncio
async def test_authentication_error_401():
    """Test 401 maps to LLMAuthenticationError."""

@pytest.mark.asyncio
async def test_authentication_error_403():
    """Test 403 maps to LLMAuthenticationError."""

@pytest.mark.asyncio
async def test_rate_limit_error_429():
    """Test 429 maps to LLMRateLimitError."""

@pytest.mark.asyncio
async def test_server_error_500():
    """Test 500 maps to LLMConnectionError."""

@pytest.mark.asyncio
async def test_timeout_error():
    """Test timeout maps to LLMTimeoutError."""

# Retry tests
@pytest.mark.asyncio
async def test_retry_on_connection_error():
    """Test retries on transient connection errors."""

@pytest.mark.asyncio
async def test_retry_on_rate_limit():
    """Test retries on rate limit with backoff."""

@pytest.mark.asyncio
async def test_no_retry_on_auth_error():
    """Test no retry on authentication errors."""

# Integration test (with mocked manager)
@pytest.mark.asyncio
async def test_manager_fallback_to_gemini():
    """Test manager falls back to Gemini when DeepSeek fails."""
```

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2026-01-02 | 0.1 | Initial story draft | Bob (SM Agent) |
| 2026-01-02 | 1.0 | Implementation complete - All tasks done, 35 tests passing | James (Dev Agent) |

---

## Dev Agent Record

### Agent Model Used
Claude Opus 4.5 (claude-opus-4-5-20251101)

### Debug Log References
- All 35 unit tests passed on first run
- Full LLM test suite: 100/100 tests passed
- Ruff linting: All checks passed (after fixing unused import)

### Completion Notes List
- GeminiProvider implemented following DeepSeek patterns
- Vision/PDF interface parameters added as Phase 2 stubs with warning logs
- Manager updated to register Gemini as fallback provider
- Token usage correctly calculates Gemini pricing ($0.075/1M input, $0.30/1M output)
- Error handling maps all specified HTTP status codes to LLM exception hierarchy
- Retry logic with exponential backoff implemented for transient errors

### File List
**Created:**
- `backend/app/services/llm/providers/gemini.py` - GeminiProvider implementation
- `backend/app/tests/test_services/test_llm/test_gemini.py` - 35 unit tests

**Modified:**
- `backend/app/services/llm/providers/__init__.py` - Export GeminiProvider
- `backend/app/services/llm/__init__.py` - Export GeminiProvider
- `backend/app/services/llm/manager.py` - Register Gemini in create_default_manager()

---

## QA Results
_To be filled by QA agent_
