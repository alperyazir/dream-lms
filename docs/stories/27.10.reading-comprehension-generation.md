# Story 27.10: Reading Comprehension Generation

**Status:** Ready for Review

**Epic:** Epic 27 - DreamAI - AI-Powered Content Generation
**Story Points:** 13
**Priority:** High
**Dependencies:** Stories 27.1-27.7 (LLM/TTS Provider Layers + DCS AI Service Client), Story 27.9 (MCQ patterns)

---

## Story

**As a** teacher,
**I want** to generate reading comprehension activities from actual book module content,
**so that** my students can practice reading skills with familiar text passages from their textbooks.

---

## Acceptance Criteria

1. [x] **MUST use actual book module content** (not AI-generated passages)
2. [x] Display passage from selected module
3. [x] Generate comprehension questions about the passage
4. [x] Question types: MCQ, True/False, Short Answer
5. [x] Source reference (module, page numbers)
6. [x] Difficulty based on module's CEFR level
7. [x] Configurable number of questions per passage

---

## Tasks / Subtasks

### Backend Tasks

- [x] **Task 1: Create Reading Comprehension Schemas** (AC: 1, 2, 3, 4, 5, 6, 7)
  - [x] Create `backend/app/schemas/reading_comprehension.py`
  - [x] Define `ReadingComprehensionRequest` Pydantic model:
    - `book_id: int` (required)
    - `module_id: int` (single module - passage source)
    - `question_count: int` (1-10, default: 5)
    - `question_types: list[Literal["mcq", "true_false", "short_answer"]]` (default: all)
    - `difficulty: Literal["auto", "easy", "medium", "hard"] = "auto"` (auto uses module CEFR)
  - [x] Define `ReadingComprehensionQuestion` model:
    - `question_id: str` (UUID)
    - `question_type: str` ("mcq", "true_false", "short_answer")
    - `question_text: str`
    - `options: list[str] | None` (for MCQ/True-False)
    - `correct_answer: str`
    - `correct_index: int | None` (for MCQ/True-False)
    - `explanation: str`
    - `passage_reference: str` (quote from passage)
  - [x] Define `ReadingComprehensionActivity` model:
    - `activity_id: str` (UUID)
    - `book_id: int`
    - `module_id: int`
    - `module_title: str`
    - `passage: str` (actual text from module)
    - `passage_pages: list[int]`
    - `questions: list[ReadingComprehensionQuestion]`
    - `difficulty: str`
    - `language: str`
    - `created_at: datetime`
  - [x] Define `ReadingComprehensionSubmission` model
  - [x] Define `ReadingComprehensionResult` model

- [x] **Task 2: Create Reading Comprehension Service** (AC: 1, 2, 3, 4, 5, 6)
  - [x] Create `backend/app/services/ai_generation/reading_comprehension_service.py`
  - [x] Implement `ReadingComprehensionService` class:
    - Constructor accepts `DCSAIServiceClient`, `LLMManager`
    - `async generate_activity(request: ReadingComprehensionRequest) -> ReadingComprehensionActivity`
  - [x] Implement passage extraction:
    - Fetch module via `DCSAIServiceClient.get_module(book_id, module_id)`
    - Extract and clean passage text
    - Preserve page references
    - **CRITICAL: Use actual text, no AI generation of passage**
  - [x] Implement difficulty mapping:
    - `auto` → use module's CEFR level (A1/A2=easy, B1=medium, B2+=hard)
    - Manual override available
  - [x] Implement question generation:
    - Use LLM to generate questions ABOUT the passage
    - Request specific question types
    - Include passage quotes for reference

- [x] **Task 3: Create Reading Comprehension Prompts** (AC: 3, 4)
  - [x] Create `backend/app/services/ai_generation/prompts/reading_prompts.py`
  - [x] Define `READING_SYSTEM_PROMPT`:
    - Role as reading comprehension expert
    - Question type guidelines
    - Bloom's taxonomy alignment
  - [x] Define `READING_USER_PROMPT_TEMPLATE`:
    - Include full passage
    - Question count and type requirements
    - Difficulty level
  - [x] Define question type schemas:
    - MCQ: question + 4 options + correct_index + explanation
    - True/False: statement + true/false + explanation
    - Short Answer: question + expected_answer + explanation
  - [x] Define difficulty guidelines:
    - Easy: Literal comprehension, find-in-text answers
    - Medium: Inferential, understand relationships
    - Hard: Evaluative, synthesis, critical analysis

- [x] **Task 4: Create Reading Comprehension API Endpoints** (AC: All)
  - [x] Add to `backend/app/api/routes/ai_generation.py`:
  - [x] Implement `POST /api/v1/ai/reading/generate` endpoint:
    - Request: `ReadingComprehensionRequest`
    - Response: `ReadingComprehensionActivity`
    - Requires teacher/supervisor/admin role
  - [x] Implement `GET /api/v1/ai/reading/{activity_id}` endpoint:
    - Returns activity with passage but without answers
    - Strip `correct_answer`, `correct_index`, `explanation`
  - [x] Implement `POST /api/v1/ai/reading/{activity_id}/submit` endpoint:
    - Request: `ReadingComprehensionSubmission`
    - Response: `ReadingComprehensionResult`
    - Grade short answers with fuzzy matching
  - [x] Implement `GET /api/v1/ai/reading/{activity_id}/result` endpoint

- [x] **Task 5: Implement Short Answer Grading** (AC: 4)
  - [x] Create `backend/app/services/ai_generation/short_answer_grader.py`
  - [x] Implement fuzzy matching for short answers:
    - Normalize text (lowercase, strip punctuation)
    - Calculate similarity score
    - Accept answers above threshold (e.g., 80% match)
  - [x] Optional: LLM-based grading for complex answers
    - Use LLM to compare student answer with expected
    - Return partial credit where applicable

- [x] **Task 6: Extend Quiz Storage Service** (AC: All)
  - [x] Extend `quiz_storage_service.py` for reading activities:
  - [x] Add `async save_reading_activity(activity: ReadingComprehensionActivity) -> str`
  - [x] Add `async get_reading_activity(activity_id: str) -> ReadingComprehensionActivity | None`
  - [x] Add submission/result storage methods

- [x] **Task 7: Write Backend Unit Tests** (AC: All)
  - [x] Create `backend/app/tests/test_services/test_ai_generation/test_reading_comprehension_service.py`
  - [x] Test passage extraction preserves original text
  - [x] Test question generation for each type
  - [x] Test difficulty auto-detection from CEFR
  - [x] Test short answer grading logic
  - [x] Add API tests for reading endpoints

### Frontend Tasks

- [x] **Task 8: Create Reading Comprehension Types** (AC: All)
  - [x] Create `frontend/src/types/reading-comprehension.ts`
  - [x] Define TypeScript interfaces:
    - `ReadingComprehensionRequest`
    - `ReadingComprehensionActivity`
    - `ReadingComprehensionQuestion`
    - `ReadingComprehensionSubmission`
    - `ReadingComprehensionResult`

- [x] **Task 9: Create Reading Comprehension API Service** (AC: All)
  - [x] Create `frontend/src/services/readingComprehensionApi.ts`
  - [x] Implement all CRUD operations

- [x] **Task 10: Create Reading Comprehension Player Component** (AC: 2, 3, 4)
  - [x] Create `frontend/src/components/ActivityPlayers/ReadingComprehensionPlayer.tsx`
  - [x] Layout:
    - Split view: Passage on left/top, Questions on right/bottom
    - Scrollable passage with highlighting on hover
    - Sticky passage on desktop for easy reference
  - [x] Passage display:
    - Show module title and page range
    - Highlight quoted text when answering related question
    - Font size controls for accessibility
  - [x] Question rendering by type:
    - MCQ: Radio button options
    - True/False: Two-button toggle
    - Short Answer: Text input field
  - [x] Progress tracking:
    - Question counter
    - Answered/unanswered indicators
  - [x] Submit when all questions answered

- [x] **Task 11: Create Reading Comprehension Results Component** (AC: 3, 4)
  - [x] Create `frontend/src/components/ActivityPlayers/ReadingComprehensionResults.tsx`
  - [x] Display overall score
  - [x] For each question:
    - Show question and student's answer
    - Show correct answer
    - Highlight passage reference quote
    - Show explanation
  - [x] Score breakdown by question type
  - [x] Actions: Try Again, Back to Generator

- [x] **Task 12: Create Reading Comprehension Form** (AC: 1, 5, 6, 7)
  - [x] Create `frontend/src/components/DreamAI/ReadingComprehensionForm.tsx`
  - [x] Book selector
  - [x] Module selector (single select - one passage per activity)
  - [x] Preview passage snippet before generation
  - [x] Question count slider (1-10)
  - [x] Question type checkboxes (MCQ, True/False, Short Answer)
  - [x] Difficulty selector (Auto/Easy/Medium/Hard)
  - [x] Generate button with loading state

- [x] **Task 13: Create Reading Comprehension Container** (AC: All)
  - [x] Create `frontend/src/components/DreamAI/ReadingComprehensionContainer.tsx`
  - [x] State flow: Form → Generating → Player → Results
  - [x] Export from index.ts

- [x] **Task 14: Write Frontend Tests** (AC: All)
  - [x] Create `ReadingComprehensionPlayer.test.tsx`
  - [x] Test passage display with highlighting
  - [x] Test each question type rendering
  - [x] Test answer input handling
  - [x] Create `ReadingComprehensionResults.test.tsx`

---

## Dev Notes

### Critical Requirement: Use Actual Book Content
[Source: Epic PRD - Story 27.10]

**This story has a CRITICAL difference from AI Quiz (27.9):**
- 27.9 (AI Quiz): LLM generates questions from module content
- 27.10 (Reading): LLM generates questions, but passage MUST be actual book text

The passage displayed to students must be the exact text from the book module. The AI only generates the comprehension questions, not the reading material itself.

### DCS Module Data Structure
[Source: docs/prd/epic-27-dreamai-content-generation.md]

```json
{
  "module_id": 3,
  "title": "Unit 3: Achievements",
  "text": "Full extracted text content from the module...",
  "topics": ["success", "goals", "motivation"],
  "language": "en",
  "difficulty": "B1",
  "pages": [40, 41, 42, 43, 44, 45]
}
```

### Question Type Guidelines

**MCQ (Multiple Choice):**
- 4 options (A, B, C, D)
- One clearly correct answer
- Distractors should be plausible but wrong
- Reference specific part of passage

**True/False:**
- Clear statement based on passage
- Answer must be definitively true or false
- Avoid ambiguous statements
- Include explanation of why true/false

**Short Answer:**
- Open-ended but with expected answer
- Accept variations in wording
- Typically 1-3 words or short phrase
- Use fuzzy matching for grading

### CEFR to Difficulty Mapping

| Module CEFR | Auto Difficulty | Question Complexity |
|-------------|-----------------|---------------------|
| A1, A2 | Easy | Literal comprehension |
| B1 | Medium | Inferential |
| B2, C1, C2 | Hard | Evaluative/Critical |

### Passage Reference Implementation

Questions should include passage references for post-submission review:

```python
{
  "question_text": "Why did the protagonist decide to leave?",
  "passage_reference": "\"I knew then that staying would mean giving up everything I'd worked for.\"",
  "explanation": "The passage explicitly states the protagonist's reasoning in paragraph 3."
}
```

### Short Answer Grading Algorithm

```python
from difflib import SequenceMatcher

def grade_short_answer(student_answer: str, expected_answer: str, threshold: float = 0.8) -> tuple[bool, float]:
    """
    Grade short answer using fuzzy matching.

    Returns: (is_correct, similarity_score)
    """
    # Normalize both answers
    student_norm = normalize_text(student_answer)
    expected_norm = normalize_text(expected_answer)

    # Calculate similarity
    similarity = SequenceMatcher(None, student_norm, expected_norm).ratio()

    return (similarity >= threshold, similarity)

def normalize_text(text: str) -> str:
    """Normalize text for comparison."""
    import re
    text = text.lower().strip()
    text = re.sub(r'[^\w\s]', '', text)  # Remove punctuation
    text = re.sub(r'\s+', ' ', text)  # Normalize whitespace
    return text
```

### API Endpoints

| Method | Endpoint | Description | Auth |
|--------|----------|-------------|------|
| POST | `/api/v1/ai/reading/generate` | Generate reading activity | Teacher+ |
| GET | `/api/v1/ai/reading/{activity_id}` | Get activity (no answers) | Student+ |
| POST | `/api/v1/ai/reading/{activity_id}/submit` | Submit answers | Student+ |
| GET | `/api/v1/ai/reading/{activity_id}/result` | Get results | Student+ |

### Source Tree Reference

**New files to create:**
```
backend/app/
├── schemas/
│   └── reading_comprehension.py
├── services/
│   └── ai_generation/
│       ├── reading_comprehension_service.py
│       ├── short_answer_grader.py
│       └── prompts/
│           └── reading_prompts.py
└── tests/
    └── test_services/
        └── test_ai_generation/
            └── test_reading_comprehension_service.py

frontend/src/
├── types/
│   └── reading-comprehension.ts
├── services/
│   └── readingComprehensionApi.ts
└── components/
    ├── ActivityPlayers/
    │   ├── ReadingComprehensionPlayer.tsx
    │   ├── ReadingComprehensionPlayer.test.tsx
    │   ├── ReadingComprehensionResults.tsx
    │   └── ReadingComprehensionResults.test.tsx
    └── DreamAI/
        ├── ReadingComprehensionForm.tsx
        └── ReadingComprehensionContainer.tsx
```

### UI Layout Reference

```
┌─────────────────────────────────────────────────────────────────────┐
│  Reading Comprehension: Unit 3 - Achievements (Pages 40-45)         │
├──────────────────────────────────┬──────────────────────────────────┤
│                                  │                                  │
│  PASSAGE                         │  QUESTIONS                       │
│  ────────                        │  ──────────                      │
│  [Scrollable area with actual    │  Q1 (MCQ):                       │
│   book text from the module]     │  Why did the protagonist...?     │
│                                  │  ○ A) Because he was tired       │
│  "I knew then that staying       │  ● B) To pursue his dreams       │
│   would mean giving up           │  ○ C) He had no choice           │
│   everything I'd worked for."    │  ○ D) For financial reasons      │
│                                  │                                  │
│  The next morning, Sarah         │  Q2 (True/False):                │
│  woke to find...                 │  Sarah was happy about leaving.  │
│                                  │  [True] [False]                  │
│                                  │                                  │
│                                  │  Q3 (Short Answer):              │
│                                  │  What did Sarah find the next    │
│                                  │  morning?                        │
│                                  │  [________________]              │
│                                  │                                  │
│                                  │  Progress: 1/5 answered          │
│                                  │  [Submit Quiz]                   │
└──────────────────────────────────┴──────────────────────────────────┘
```

---

## Testing

### Test File Locations
```
backend/app/tests/test_services/test_ai_generation/test_reading_comprehension_service.py
backend/app/tests/test_api/test_ai_generation.py (extend)
frontend/src/components/ActivityPlayers/ReadingComprehensionPlayer.test.tsx
frontend/src/components/ActivityPlayers/ReadingComprehensionResults.test.tsx
```

### Backend Test Cases

```python
# test_reading_comprehension_service.py

@pytest.mark.asyncio
async def test_generate_preserves_original_passage():
    """Critical: Ensure passage is actual book text, not AI-generated."""

@pytest.mark.asyncio
async def test_generate_mcq_questions():
    """Test MCQ question generation."""

@pytest.mark.asyncio
async def test_generate_true_false_questions():
    """Test True/False question generation."""

@pytest.mark.asyncio
async def test_generate_short_answer_questions():
    """Test short answer question generation."""

@pytest.mark.asyncio
async def test_difficulty_auto_detection():
    """Test CEFR to difficulty mapping."""

@pytest.mark.asyncio
async def test_short_answer_grading_exact_match():
    """Test exact match gets full credit."""

@pytest.mark.asyncio
async def test_short_answer_grading_fuzzy_match():
    """Test similar answer gets credit."""

@pytest.mark.asyncio
async def test_short_answer_grading_wrong_answer():
    """Test wrong answer gets no credit."""
```

### Frontend Test Cases

```typescript
// ReadingComprehensionPlayer.test.tsx
describe('ReadingComprehensionPlayer', () => {
  it('displays passage with module title and pages')
  it('renders MCQ questions with radio options')
  it('renders True/False with toggle buttons')
  it('renders Short Answer with text input')
  it('highlights passage quote when question focused')
  it('tracks answered questions')
  it('submits all answers')
})

// ReadingComprehensionResults.test.tsx
describe('ReadingComprehensionResults', () => {
  it('displays overall score')
  it('shows passage reference for each question')
  it('shows explanation for each question')
  it('handles short answer partial credit display')
})
```

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2026-01-02 | 0.1 | Initial story draft | Bob (SM Agent) |

---

## Dev Agent Record

### Agent Model Used
Claude Opus 4.5 (claude-opus-4-5-20251101)

### Debug Log References
- Backend tests: 48 passed (27 short answer grader tests + 8 reading service tests + 13 API/storage tests)
- Frontend tests: 71 passed (33 ReadingComprehensionPlayer tests + 38 ReadingComprehensionResults tests)

### Completion Notes List
1. Implemented full reading comprehension feature following Story 27.9 (AI Quiz) patterns
2. CRITICAL: Passage uses actual book module text (not AI-generated) per story requirements
3. LLM only generates comprehension questions about the passage
4. Short answer grading uses fuzzy matching with SequenceMatcher (80% threshold)
5. CEFR to difficulty mapping: A1/A2→easy, B1→medium, B2/C1/C2→hard
6. Score breakdown by question type (MCQ, True/False, Short Answer)
7. Split-view UI with passage and questions panels
8. All acceptance criteria verified through tests

### File List
**Backend (New Files):**
- `backend/app/schemas/reading_comprehension.py`
- `backend/app/services/ai_generation/reading_comprehension_service.py`
- `backend/app/services/ai_generation/short_answer_grader.py`
- `backend/app/services/ai_generation/prompts/reading_prompts.py`
- `backend/app/tests/test_services/test_reading_comprehension/__init__.py`
- `backend/app/tests/test_services/test_reading_comprehension/test_short_answer_grader.py`
- `backend/app/tests/test_services/test_reading_comprehension/test_reading_service.py`
- `backend/app/tests/test_api/test_reading_comprehension.py`

**Backend (Modified Files):**
- `backend/app/api/routes/ai_generation.py` - Added reading comprehension endpoints
- `backend/app/services/ai_generation/quiz_storage_service.py` - Added reading activity storage
- `backend/app/services/ai_generation/__init__.py` - Added reading comprehension exports
- `backend/app/services/ai_generation/prompts/__init__.py` - Added reading prompts exports

**Frontend (New Files):**
- `frontend/src/types/reading-comprehension.ts`
- `frontend/src/services/readingComprehensionApi.ts`
- `frontend/src/components/ActivityPlayers/ReadingComprehensionPlayer.tsx`
- `frontend/src/components/ActivityPlayers/ReadingComprehensionPlayer.test.tsx`
- `frontend/src/components/ActivityPlayers/ReadingComprehensionResults.tsx`
- `frontend/src/components/ActivityPlayers/ReadingComprehensionResults.test.tsx`
- `frontend/src/components/DreamAI/ReadingComprehensionForm.tsx`
- `frontend/src/components/DreamAI/ReadingComprehensionContainer.tsx`

---

## QA Results
_To be filled by QA agent_
