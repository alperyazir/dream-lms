# Story 27.9: AI Quiz Generation (MCQ)

**Status:** Complete

**Epic:** Epic 27 - DreamAI - AI-Powered Content Generation
**Story Points:** 13
**Priority:** High
**Dependencies:** Stories 27.1-27.7 (LLM/TTS Provider Layers + DCS AI Service Client), Story 27.8 (Quiz patterns)

---

## Story

**As a** teacher,
**I want** to generate multiple-choice questions from book module content using AI,
**so that** I can quickly create comprehension quizzes without manually writing questions and distractors.

---

## Acceptance Criteria

1. [x] Select one or multiple modules as source
2. [x] Difficulty level selection (easy, medium, hard)
3. [x] Question count configuration (1-20)
4. [x] Language detection and matching
5. [x] Plausible distractor generation using LLM
6. [x] Output in activity-compatible JSON format
7. [x] Include explanations for correct answers
8. [x] Show answers only after entire quiz is submitted

---

## Tasks / Subtasks

### Backend Tasks

- [x] **Task 1: Create AI Quiz Schemas** (AC: 1, 2, 3, 6, 7)
  - [ ] Create `backend/app/schemas/ai_quiz.py`
  - [ ] Define `AIQuizGenerationRequest` Pydantic model:
    - `book_id: int` (required)
    - `module_ids: list[int]` (at least one required)
    - `difficulty: Literal["easy", "medium", "hard"]` (default: "medium")
    - `question_count: int` (1-20, default: 10)
    - `language: str | None` (auto-detect if not provided)
    - `include_explanations: bool = True`
  - [ ] Define `AIQuizQuestion` model:
    - `question_id: str` (UUID)
    - `question_text: str`
    - `options: list[str]` (4 options)
    - `correct_answer: str`
    - `correct_index: int` (0-3)
    - `explanation: str | None`
    - `source_module_id: int`
    - `source_page: int | None`
    - `difficulty: str`
  - [ ] Define `AIQuiz` model:
    - `quiz_id: str` (UUID)
    - `book_id: int`
    - `module_ids: list[int]`
    - `questions: list[AIQuizQuestion]`
    - `difficulty: str`
    - `language: str`
    - `created_at: datetime`
  - [ ] Define `AIQuizSubmission` model for student answers
  - [ ] Define `AIQuizResult` model with explanations revealed

- [x] **Task 2: Create AI Quiz Generation Service** (AC: 1, 2, 3, 4, 5, 6, 7)
  - [ ] Create `backend/app/services/ai_generation/ai_quiz_service.py`
  - [ ] Implement `AIQuizService` class:
    - Constructor accepts `DCSAIServiceClient`, `LLMManager`
    - `async generate_quiz(request: AIQuizGenerationRequest) -> AIQuiz`
  - [ ] Implement module content fetching:
    - Use `DCSAIServiceClient.get_module(book_id, module_id)` for each module
    - Combine text content from selected modules
    - Extract language from module metadata
  - [ ] Implement LLM prompt construction:
    - Create system prompt for MCQ generation
    - Include difficulty guidelines (easy/medium/hard)
    - Request structured JSON output
    - Include source text context
  - [ ] Implement question generation:
    - Use `LLMManager.generate_structured()` with JSON schema
    - Parse and validate LLM response
    - Map questions to source modules
  - [ ] Handle edge cases:
    - Module not found → raise `DCSAIDataNotFoundError`
    - LLM failure → raise `QuizGenerationError`
    - Invalid response format → retry with clearer prompt

- [x] **Task 3: Create LLM Prompt Templates** (AC: 2, 5, 7)
  - [ ] Create `backend/app/services/ai_generation/prompts/` directory
  - [ ] Create `backend/app/services/ai_generation/prompts/__init__.py`
  - [ ] Create `backend/app/services/ai_generation/prompts/mcq_prompts.py`
  - [ ] Define `MCQ_SYSTEM_PROMPT` with:
    - Role as educational content creator
    - MCQ format requirements
    - Distractor generation guidelines
    - Explanation writing guidelines
  - [ ] Define `MCQ_USER_PROMPT_TEMPLATE` with:
    - Source text placeholder
    - Question count placeholder
    - Difficulty level placeholder
    - Language specification
  - [ ] Define `MCQ_JSON_SCHEMA` for structured output:
    ```python
    {
      "type": "object",
      "properties": {
        "questions": {
          "type": "array",
          "items": {
            "type": "object",
            "properties": {
              "question": {"type": "string"},
              "options": {"type": "array", "items": {"type": "string"}, "minItems": 4, "maxItems": 4},
              "correct_index": {"type": "integer", "minimum": 0, "maximum": 3},
              "explanation": {"type": "string"}
            },
            "required": ["question", "options", "correct_index", "explanation"]
          }
        }
      }
    }
    ```
  - [ ] Define difficulty-specific guidelines:
    - Easy: Basic recall, obvious distractors
    - Medium: Application, similar but wrong distractors
    - Hard: Analysis/synthesis, very plausible distractors

- [x] **Task 4: Create AI Quiz API Endpoints** (AC: All)
  - [ ] Add to `backend/app/api/routes/ai_generation.py`:
  - [ ] Implement `POST /api/v1/ai/quiz/generate` endpoint:
    - Request body: `AIQuizGenerationRequest`
    - Response: `AIQuiz`
    - Requires teacher/supervisor/admin role
    - Log token usage for cost tracking
  - [ ] Implement `GET /api/v1/ai/quiz/{quiz_id}` endpoint:
    - Returns quiz without correct answers (for students)
    - Strip `correct_answer`, `correct_index`, `explanation` from response
  - [ ] Implement `POST /api/v1/ai/quiz/{quiz_id}/submit` endpoint:
    - Request: `AIQuizSubmission`
    - Response: `AIQuizResult` with all answers and explanations
    - Calculate score
  - [ ] Implement `GET /api/v1/ai/quiz/{quiz_id}/result` endpoint:
    - Returns results with explanations after submission

- [x] **Task 5: Extend Quiz Storage Service** (AC: 8)
  - [ ] Extend `backend/app/services/ai_generation/quiz_storage_service.py`
  - [ ] Add `async save_ai_quiz(quiz: AIQuiz) -> str`
  - [ ] Add `async get_ai_quiz(quiz_id: str) -> AIQuiz | None`
  - [ ] Add `async save_ai_quiz_submission(quiz_id: str, student_id: UUID, answers: dict) -> AIQuizResult`
  - [ ] Add `async get_ai_quiz_result(quiz_id: str, student_id: UUID) -> AIQuizResult | None`

- [x] **Task 6: Write Backend Unit Tests** (AC: All)
  - [ ] Create `backend/app/tests/test_services/test_ai_generation/test_ai_quiz_service.py`
  - [ ] Test quiz generation with mocked LLM:
    - Test successful generation
    - Test difficulty levels affect prompt
    - Test multi-module content combination
    - Test language detection
  - [ ] Test LLM response parsing:
    - Test valid JSON parsing
    - Test invalid response handling
    - Test retry logic
  - [ ] Add API tests to `backend/app/tests/test_api/test_ai_generation.py`:
    - Test generate endpoint auth
    - Test quiz retrieval strips answers
    - Test submission scoring

### Frontend Tasks

- [x] **Task 7: Create AI Quiz Types** (AC: All)
  - [ ] Create/extend `frontend/src/types/ai-quiz.ts`
  - [ ] Define TypeScript interfaces:
    - `AIQuizGenerationRequest`
    - `AIQuiz`
    - `AIQuizQuestion`
    - `AIQuizSubmission`
    - `AIQuizResult`

- [x] **Task 8: Create AI Quiz API Service** (AC: All)
  - [ ] Create `frontend/src/services/aiQuizApi.ts`
  - [ ] Implement `generateAIQuiz(request: AIQuizGenerationRequest): Promise<AIQuiz>`
  - [ ] Implement `getAIQuiz(quizId: string): Promise<AIQuiz>`
  - [ ] Implement `submitAIQuiz(quizId: string, answers: Record<string, number>): Promise<AIQuizResult>`
  - [ ] Implement `getAIQuizResult(quizId: string): Promise<AIQuizResult>`

- [x] **Task 9: Create AI Quiz Player Component** (AC: 8)
  - [ ] Create `frontend/src/components/ActivityPlayers/AIQuizPlayer.tsx`
  - [ ] Display one question at a time:
    - Show question text prominently
    - Display 4 options as clickable cards
    - Highlight selected option
    - No correct/incorrect feedback during quiz
  - [ ] Implement navigation:
    - Next/Previous buttons
    - Question progress indicator
    - Jump to question (optional clickable dots)
  - [ ] State management:
    - Track selected answer index per question
    - Allow changing answers before submission
  - [ ] Submit button:
    - Only enabled when all questions answered
    - Confirmation dialog before submission

- [x] **Task 10: Create AI Quiz Results Component** (AC: 7, 8)
  - [ ] Create `frontend/src/components/ActivityPlayers/AIQuizResults.tsx`
  - [ ] Display results after submission:
    - Overall score with percentage
    - Score breakdown by difficulty (if mixed)
  - [ ] For each question show:
    - Question text
    - All options with indicators:
      - Correct answer (green checkmark)
      - Student's wrong answer (red X)
    - Explanation for correct answer
    - Source module reference
  - [ ] Actions:
    - "Try Again" button
    - "Back to Generator" button
    - "Save to Assignment" button (future)

- [x] **Task 11: Create AI Quiz Configuration Form** (AC: 1, 2, 3, 4)
  - [ ] Create `frontend/src/components/DreamAI/AIQuizForm.tsx`
  - [ ] Book selector dropdown
  - [ ] Module multi-select with "Select All" option
  - [ ] Difficulty radio buttons (Easy/Medium/Hard)
  - [ ] Question count slider or dropdown (1-20)
  - [ ] Language indicator (auto-detected from modules)
  - [ ] Generate button with loading state
  - [ ] Estimated generation time indicator
  - [ ] Error handling with retry option

- [x] **Task 12: Create AI Quiz Container** (AC: All)
  - [ ] Create `frontend/src/components/DreamAI/AIQuizContainer.tsx`
  - [ ] Manage state flow: Form → Generating → Player → Results
  - [ ] Handle errors with user-friendly messages
  - [ ] Export from `frontend/src/components/DreamAI/index.ts`

- [x] **Task 13: Write Frontend Tests** (AC: All)
  - [ ] Create `frontend/src/components/ActivityPlayers/AIQuizPlayer.test.tsx`
  - [ ] Test question display and navigation
  - [ ] Test no feedback shown during quiz
  - [ ] Test submission flow
  - [ ] Create `frontend/src/components/ActivityPlayers/AIQuizResults.test.tsx`
  - [ ] Test results display with explanations
  - [ ] Test score calculation display

---

## Dev Notes

### Previous Story Insights
[Source: docs/stories/27.8.vocabulary-quiz-generation.md]

**From Story 27.8 (Vocabulary Quiz):**
- Quiz storage service pattern established in `quiz_storage_service.py`
- API endpoint patterns in `ai_generation.py` router
- Frontend patterns: Player + Results + Form + Container
- Answer revelation only after submission

**From Story 27.7 (DCS AI Service Client):**
- `DCSAIServiceClient.get_module(book_id, module_id)` returns module with text content
- Module includes: text, topics, vocabulary_ids, language, difficulty
- Factory function `get_dcs_ai_client` for dependency injection

**From Story 27.1 (LLM Provider Layer):**
- Use `LLMManager.generate_structured()` for JSON output with schema
- Automatic fallback between providers
- Token usage tracking available

### DCS Module Data Structure
[Source: docs/prd/epic-27-dreamai-content-generation.md]

```json
{
  "module_id": 3,
  "title": "Unit 3: Achievements",
  "text": "Full extracted text content from the module...",
  "topics": ["success", "goals", "motivation"],
  "vocabulary_ids": ["vocab_123", "vocab_456"],
  "language": "en",
  "difficulty": "B1",
  "pages": [40, 41, 42, 43, 44, 45]
}
```

### LLM Prompt Design Guidelines
[Source: Best practices for MCQ generation]

**System Prompt Elements:**
1. Role definition (educational assessment expert)
2. Output format (strict JSON)
3. Quality criteria for questions
4. Distractor generation rules:
   - Must be plausible but clearly wrong
   - Similar length to correct answer
   - No "all of the above" or "none of the above"
   - Avoid negative phrasing

**Difficulty Calibration:**
- **Easy:** Direct fact recall from text, obvious wrong answers
- **Medium:** Requires understanding concepts, some inference, plausible distractors
- **Hard:** Requires synthesis/analysis, very plausible distractors, nuanced distinctions

### Quiz Generation Algorithm
[Source: Derived from AC]

```python
async def generate_ai_quiz(request: AIQuizGenerationRequest) -> AIQuiz:
    # 1. Fetch module content from DCS
    modules_content = []
    detected_language = None
    for module_id in request.module_ids:
        module = await dcs_client.get_module(request.book_id, module_id)
        modules_content.append({
            "module_id": module.module_id,
            "title": module.title,
            "text": module.text,
            "pages": module.pages
        })
        if not detected_language:
            detected_language = module.language

    # 2. Combine content and build prompt
    combined_text = "\n\n".join([
        f"--- {m['title']} (Pages {m['pages'][0]}-{m['pages'][-1]}) ---\n{m['text']}"
        for m in modules_content
    ])

    language = request.language or detected_language or "en"

    prompt = MCQ_USER_PROMPT_TEMPLATE.format(
        source_text=combined_text,
        question_count=request.question_count,
        difficulty=request.difficulty,
        language=language
    )

    # 3. Generate questions via LLM
    response = await llm_manager.generate_structured(
        system_prompt=MCQ_SYSTEM_PROMPT,
        user_prompt=prompt,
        schema=MCQ_JSON_SCHEMA
    )

    # 4. Parse and validate response
    questions = []
    for i, q in enumerate(response["questions"][:request.question_count]):
        questions.append(AIQuizQuestion(
            question_id=str(uuid4()),
            question_text=q["question"],
            options=q["options"],
            correct_answer=q["options"][q["correct_index"]],
            correct_index=q["correct_index"],
            explanation=q.get("explanation"),
            source_module_id=modules_content[i % len(modules_content)]["module_id"],
            difficulty=request.difficulty
        ))

    return AIQuiz(
        quiz_id=str(uuid4()),
        book_id=request.book_id,
        module_ids=request.module_ids,
        questions=questions,
        difficulty=request.difficulty,
        language=language,
        created_at=datetime.utcnow()
    )
```

### API Endpoints
[Source: docs/prd/epic-27-dreamai-content-generation.md]

| Method | Endpoint | Description | Auth |
|--------|----------|-------------|------|
| POST | `/api/v1/ai/quiz/generate` | Generate AI quiz | Teacher+ |
| GET | `/api/v1/ai/quiz/{quiz_id}` | Get quiz (no answers) | Student+ |
| POST | `/api/v1/ai/quiz/{quiz_id}/submit` | Submit answers | Student+ |
| GET | `/api/v1/ai/quiz/{quiz_id}/result` | Get results with explanations | Student+ |

### Source Tree Reference

**New files to create:**
```
backend/app/
├── schemas/
│   └── ai_quiz.py                    # AI Quiz Pydantic models
├── services/
│   └── ai_generation/
│       ├── ai_quiz_service.py        # Quiz generation service
│       └── prompts/
│           ├── __init__.py
│           └── mcq_prompts.py        # LLM prompt templates
└── tests/
    └── test_services/
        └── test_ai_generation/
            └── test_ai_quiz_service.py

frontend/src/
├── types/
│   └── ai-quiz.ts
├── services/
│   └── aiQuizApi.ts
└── components/
    ├── ActivityPlayers/
    │   ├── AIQuizPlayer.tsx
    │   ├── AIQuizPlayer.test.tsx
    │   ├── AIQuizResults.tsx
    │   └── AIQuizResults.test.tsx
    └── DreamAI/
        ├── AIQuizForm.tsx
        └── AIQuizContainer.tsx
```

**Files to modify:**
```
backend/app/api/routes/ai_generation.py   # Add AI quiz endpoints
backend/app/services/ai_generation/quiz_storage_service.py  # Extend for AI quizzes
frontend/src/components/DreamAI/index.ts  # Export new components
```

### Coding Standards
[Source: docs/architecture/coding-standards.md]

**Backend:**
- Use `async/await` for all I/O operations
- Type hints required on all functions
- Pydantic models for all request/response schemas
- HTTPException with appropriate status codes

**Frontend:**
- TypeScript strict mode
- React functional components with hooks
- TanStack Query for server state
- Shadcn UI components
- Vitest for unit tests

---

## Testing

### Test File Locations
```
backend/app/tests/test_services/test_ai_generation/test_ai_quiz_service.py
backend/app/tests/test_api/test_ai_generation.py (extend)
frontend/src/components/ActivityPlayers/AIQuizPlayer.test.tsx
frontend/src/components/ActivityPlayers/AIQuizResults.test.tsx
```

### Test Standards
[Source: docs/architecture/10-testing-strategy.md]

**Backend:**
- Use `pytest` with `pytest-asyncio`
- Mock LLMManager and DCSAIServiceClient
- Test prompt construction
- Test response parsing and validation

**Frontend:**
- Use Vitest + React Testing Library
- Mock API calls
- Test user interactions
- Test state management

### Backend Test Cases

```python
# test_ai_quiz_service.py

@pytest.mark.asyncio
async def test_generate_quiz_success():
    """Test successful MCQ generation with mocked LLM."""

@pytest.mark.asyncio
async def test_generate_quiz_combines_multiple_modules():
    """Test content from multiple modules is combined."""

@pytest.mark.asyncio
async def test_generate_quiz_easy_difficulty():
    """Test easy difficulty includes appropriate prompt guidance."""

@pytest.mark.asyncio
async def test_generate_quiz_hard_difficulty():
    """Test hard difficulty includes appropriate prompt guidance."""

@pytest.mark.asyncio
async def test_generate_quiz_detects_language():
    """Test language auto-detection from module metadata."""

@pytest.mark.asyncio
async def test_generate_quiz_llm_failure():
    """Test graceful handling when LLM fails."""

@pytest.mark.asyncio
async def test_generate_quiz_invalid_response():
    """Test handling of malformed LLM response."""

# API tests
@pytest.mark.asyncio
async def test_get_quiz_strips_answers():
    """Test GET quiz endpoint doesn't expose correct answers."""

@pytest.mark.asyncio
async def test_submit_quiz_returns_explanations():
    """Test submission returns explanations for all questions."""
```

### Frontend Test Cases

```typescript
// AIQuizPlayer.test.tsx
describe('AIQuizPlayer', () => {
  it('displays question text prominently')
  it('shows 4 options as clickable cards')
  it('highlights selected option')
  it('does NOT show correct/incorrect during quiz')
  it('allows navigation between questions')
  it('tracks answered questions')
  it('enables submit only when all answered')
})

// AIQuizResults.test.tsx
describe('AIQuizResults', () => {
  it('displays overall score')
  it('shows correct answer with green indicator')
  it('shows wrong answer with red indicator')
  it('displays explanation for each question')
  it('shows source module reference')
})
```

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2026-01-02 | 0.1 | Initial story draft | Bob (SM Agent) |

---

## Dev Agent Record

### Agent Model Used
_To be filled by dev agent_

### Debug Log References
_To be filled by dev agent_

### Completion Notes List
_To be filled by dev agent_

### File List
_To be filled by dev agent_

---

## QA Results
_To be filled by QA agent_
